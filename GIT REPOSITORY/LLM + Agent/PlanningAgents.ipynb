{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import faiss\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Global System Prompt (Shared by All Agents)\n",
    "# =====================================\n",
    "SYSTEM_PROMPT = (\n",
    "    \"Provide only the most relevant factual response in 3-4 sentences (max 350 characters). \"\n",
    "    \"Do NOT include introductions, disclaimers, or statements about being an AI. \"\n",
    "    \"Do NOT include personal beliefs, opinions, or subjective statements. \"\n",
    "    \"Simply state the factual answer.\"\n",
    ")\n",
    "\n",
    "def clean_response(response_text: str) -> str:\n",
    "    \"\"\"Cleans AI-generated responses by removing common meta phrases.\"\"\"\n",
    "    remove_phrases = [\n",
    "        \"As an AI,\", \"I'm not capable of\", \"I cannot provide personal opinions\",\n",
    "        \"Based on available information\", \"I can provide a factual response\",\n",
    "        \"System: The given input\", \"The given text\", \"I believe\", \"I think\",\n",
    "        \"It is possible that\", \"I've come to the conclusion that\"\n",
    "    ]\n",
    "    for phrase in remove_phrases:\n",
    "        response_text = re.sub(rf\"(^|\\b){re.escape(phrase)}\", \"\", response_text, flags=re.IGNORECASE).strip()\n",
    "    response_text = re.sub(r\"^[,.\\s]+\", \"\", response_text)\n",
    "    if response_text and response_text[0].islower():\n",
    "        response_text = response_text.capitalize()\n",
    "    return response_text\n",
    "\n",
    "# =====================================\n",
    "# 🔹 PostgreSQL Database Configuration\n",
    "# =====================================\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Planning Taxonomy (Categories and Subcategories)\n",
    "# =====================================\n",
    "PLANNING_AGENTS = {\n",
    "    \"Planning Without Feedback\": {\n",
    "        \"Single-Path Reasoning\": [\"Chain of Thought (CoT)\", \"Zero-Shot CoT\", \"Re-Prompting\"],\n",
    "        \"Multi-Path Reasoning\": [\"ReWOO\", \"HuggingGPT\", \"Tree-of-Thought (ToT)\"],\n",
    "        \"External Planner\": [\"LLM-Planner\", \"ReAct\", \"LLM+P\"]\n",
    "    },\n",
    "    \"Planning With Feedback\": {\n",
    "        \"Environment Feedback\": [\"Inner Monologue\", \"LLM4RL\"],\n",
    "        \"Human Feedback\": [\"ChatCoT\", \"TPTU\"],\n",
    "        \"Model Feedback\": [\"Self-Refine\", \"SelfCheck\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def populate_planning_taxonomy():\n",
    "    \"\"\"\n",
    "    Inserts planning categories and subcategories from PLANNING_AGENTS dictionary into the database.\n",
    "    \"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Insert categories\n",
    "            for category in PLANNING_AGENTS.keys():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO planning_categories (name)\n",
    "                    VALUES (%s)\n",
    "                    ON CONFLICT (name) DO NOTHING;\n",
    "                \"\"\", (category,))\n",
    "            conn.commit()\n",
    "            # Insert subcategories\n",
    "            for category, subcat_dict in PLANNING_AGENTS.items():\n",
    "                cursor.execute(\"SELECT id FROM planning_categories WHERE name = %s;\", (category,))\n",
    "                cat_id = cursor.fetchone()[0]\n",
    "                for subcategory in subcat_dict.keys():\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO planning_subcategories (name, category_id)\n",
    "                        VALUES (%s, %s)\n",
    "                        ON CONFLICT (name) DO NOTHING;\n",
    "                    \"\"\", (subcategory, cat_id))\n",
    "            conn.commit()\n",
    "    print(\"✅ Planning taxonomy populated.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Logging & Custom Cursor Setup\n",
    "# --------------------------------------\n",
    "logging.basicConfig(\n",
    "    filename='executed_queries.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "class LoggingCursor(psycopg2.extensions.cursor):\n",
    "    def execute(self, sql, args=None):\n",
    "        logging.info(self.mogrify(sql, args).decode('utf-8'))\n",
    "        try:\n",
    "            super().execute(sql, args)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error executing query: {e}\")\n",
    "            raise\n",
    "\n",
    "# --------------------------------------\n",
    "# drop_existing_table function\n",
    "# --------------------------------------\n",
    "def drop_existing_table():\n",
    "    \"\"\"Drops all related tables for a clean slate.\"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS agent_pair_performance;\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS task_performance;\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS agents;\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS planning_subcategories;\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS planning_categories;\")\n",
    "            conn.commit()\n",
    "    print(\"✅ Dropped existing tables.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# setup_database function\n",
    "# --------------------------------------\n",
    "def setup_database():\n",
    "    \"\"\"Creates necessary tables in the database.\"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # planning_categories table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS planning_categories (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    name TEXT UNIQUE NOT NULL\n",
    "                );\n",
    "            \"\"\")\n",
    "            # planning_subcategories table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS planning_subcategories (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    name TEXT UNIQUE NOT NULL,\n",
    "                    category_id INT REFERENCES planning_categories(id) ON DELETE CASCADE\n",
    "                );\n",
    "            \"\"\")\n",
    "            # agents table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS agents (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    title TEXT UNIQUE NOT NULL,\n",
    "                    profile TEXT,\n",
    "                    memory TEXT,\n",
    "                    planning_category_id INT REFERENCES planning_categories(id) ON DELETE CASCADE,\n",
    "                    planning_subcategory_id INT REFERENCES planning_subcategories(id) ON DELETE CASCADE,\n",
    "                    action TEXT,\n",
    "                    capability_acquisition TEXT,\n",
    "                    social_science TEXT,\n",
    "                    natural_science TEXT,\n",
    "                    engineering TEXT,\n",
    "                    subjective TEXT,\n",
    "                    objective TEXT,\n",
    "                    benchmark TEXT,\n",
    "                    publication TEXT,\n",
    "                    code_url TEXT,\n",
    "                    paper_url TEXT,\n",
    "                    generated_response TEXT[] DEFAULT ARRAY[]::TEXT[]\n",
    "                );\n",
    "            \"\"\")\n",
    "            # task_performance table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS task_performance (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    task_name TEXT NOT NULL,\n",
    "                    planning_category_id INT REFERENCES planning_categories(id) ON DELETE CASCADE,\n",
    "                    planning_subcategory_id INT REFERENCES planning_subcategories(id) ON DELETE CASCADE,\n",
    "                    avg_euclidean_distance FLOAT,\n",
    "                    avg_cosine_similarity FLOAT,\n",
    "                    completion_time FLOAT,\n",
    "                    response_length INT,\n",
    "                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            # agent_pair_performance table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS agent_pair_performance (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    task_name TEXT NOT NULL,\n",
    "                    agent1 TEXT NOT NULL REFERENCES agents(title) ON DELETE CASCADE,\n",
    "                    agent2 TEXT NOT NULL REFERENCES agents(title) ON DELETE CASCADE,\n",
    "                    euclidean_distance FLOAT,\n",
    "                    cosine_similarity FLOAT,\n",
    "                    response_length FLOAT,\n",
    "                    completion_time FLOAT,\n",
    "                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    UNIQUE (task_name, agent1, agent2)\n",
    "                );\n",
    "            \"\"\")\n",
    "            conn.commit()\n",
    "    print(\"✅ Database setup completed.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Insert Agents from CSV\n",
    "# --------------------------------------\n",
    "def insert_agents_from_csv(csv_filepath: str):\n",
    "    \"\"\"\n",
    "    Reads agent data from a CSV file and inserts into the agents table.\n",
    "    The CSV should have columns: Title, Profile, Memory, Planning, Action, Capability Acquition, \n",
    "    Social science, Natural Science, Engineering, Subjective, Objective, Benchmark, Publication, Code, Paper,\n",
    "    and optionally Subcategory.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_filepath)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            for _, row in df.iterrows():\n",
    "                try:\n",
    "                    title = row[\"Title\"].strip()\n",
    "                    profile = row[\"Profile\"].strip() if pd.notna(row[\"Profile\"]) else None\n",
    "                    memory = row[\"Memory\"].strip() if pd.notna(row[\"Memory\"]) else None\n",
    "                    planning_text = row[\"Planning\"].strip() if pd.notna(row[\"Planning\"]) else \"Unknown\"\n",
    "                    action = row[\"Action\"].strip() if pd.notna(row[\"Action\"]) else None\n",
    "                    capability_acquisition = row[\"Capability Acquition\"].strip() if pd.notna(row[\"Capability Acquition\"]) else None\n",
    "                    social_science = row[\"Social science\"].strip() if pd.notna(row[\"Social science\"]) else None\n",
    "                    natural_science = row[\"Natural Science\"].strip() if pd.notna(row[\"Natural Science\"]) else None\n",
    "                    engineering = row[\"Engineering\"].strip() if pd.notna(row[\"Engineering\"]) else None\n",
    "                    subjective = row[\"Subjective\"].strip() if pd.notna(row[\"Subjective\"]) else None\n",
    "                    objective = row[\"Objective\"].strip() if pd.notna(row[\"Objective\"]) else None\n",
    "                    benchmark = row[\"Benchmark\"].strip() if pd.notna(row[\"Benchmark\"]) else None\n",
    "                    publication = row[\"Publication\"].strip() if pd.notna(row[\"Publication\"]) else None\n",
    "                    code_url = row[\"Code\"].strip() if pd.notna(row[\"Code\"]) else None\n",
    "                    paper_url = row[\"Paper\"].strip() if pd.notna(row[\"Paper\"]) else None\n",
    "\n",
    "                    # Look up planning category id\n",
    "                    cursor.execute(\"SELECT id FROM planning_categories WHERE name = %s;\", (planning_text,))\n",
    "                    cat = cursor.fetchone()\n",
    "                    planning_category_id = cat[0] if cat else None\n",
    "\n",
    "                    # Optional: Look for a \"Subcategory\" column\n",
    "                    planning_subcategory_id = None\n",
    "                    if \"Subcategory\" in df.columns:\n",
    "                        subcat_text = row[\"Subcategory\"].strip() if pd.notna(row[\"Subcategory\"]) else None\n",
    "                        if subcat_text:\n",
    "                            cursor.execute(\"SELECT id FROM planning_subcategories WHERE name = %s;\", (subcat_text,))\n",
    "                            subcat = cursor.fetchone()\n",
    "                            if subcat:\n",
    "                                planning_subcategory_id = subcat[0]\n",
    "                    \n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO agents (\n",
    "                            title, profile, memory, planning_category_id, planning_subcategory_id,\n",
    "                            action, capability_acquisition, social_science, natural_science, engineering,\n",
    "                            subjective, objective, benchmark, publication, code_url, paper_url, generated_response\n",
    "                        )\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, ARRAY[]::TEXT[])\n",
    "                        ON CONFLICT (title) DO NOTHING;\n",
    "                    \"\"\", (\n",
    "                        title, profile, memory, planning_category_id, planning_subcategory_id,\n",
    "                        action, capability_acquisition, social_science, natural_science, engineering,\n",
    "                        subjective, objective, benchmark, publication, code_url, paper_url\n",
    "                    ))\n",
    "                    print(f\"✅ Inserted: {title}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error inserting {row.get('Title', 'Unknown')}: {e}\")\n",
    "                    conn.rollback()\n",
    "                else:\n",
    "                    conn.commit()\n",
    "\n",
    "# --------------------------------------\n",
    "# Database Storage Functions for Agent Responses\n",
    "# --------------------------------------\n",
    "def update_generated_response(agent_title: str, new_response: str):\n",
    "    \"\"\"\n",
    "    Appends a new response to the generated_response array for a specific agent.\n",
    "    \"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT id, generated_response FROM agents WHERE title = %s;\", (agent_title,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                agent_id = result[0]\n",
    "                current_responses = result[1] if result[1] is not None else []\n",
    "                print(f\"Before update, generated_response for '{agent_title}': {current_responses}\")\n",
    "                cursor.execute(\n",
    "                    \"UPDATE agents SET generated_response = generated_response || %s::text[] WHERE id = %s;\",\n",
    "                    ([new_response], agent_id)\n",
    "                )\n",
    "                print(f\"✅ Appended new response '{new_response}' to agent '{agent_title}'.\")\n",
    "            else:\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO agents (title, generated_response) VALUES (%s, ARRAY[%s]::text[]) ON CONFLICT (title) DO NOTHING;\",\n",
    "                    (agent_title, new_response)\n",
    "                )\n",
    "                print(f\"✅ Inserted new agent '{agent_title}' with initial response '{new_response}'.\")\n",
    "        conn.commit()\n",
    "\n",
    "def store_agent_response(agent_name: str, response: str):\n",
    "    \"\"\"Stores or updates an agent's response in the database.\"\"\"\n",
    "    if isinstance(response, dict):\n",
    "        response = json.dumps(response)\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT generated_response FROM agents WHERE title = %s\", (agent_name,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                current_responses = result[0] or []\n",
    "                if response not in current_responses:\n",
    "                    cursor.execute(\"\"\"\n",
    "                        UPDATE agents \n",
    "                        SET generated_response = generated_response || ARRAY[%s]::text[]\n",
    "                        WHERE title = %s\n",
    "                    \"\"\", (response, agent_name))\n",
    "                    print(f\"✅ Response appended for agent: {agent_name} - {response}\")\n",
    "            else:\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO agents (title, generated_response)\n",
    "                    VALUES (%s, ARRAY[%s]::text[])\n",
    "                \"\"\", (agent_name, response))\n",
    "                print(f\"✅ New response stored for agent: {agent_name} - {response}\")\n",
    "        conn.commit()\n",
    "\n",
    "# --------------------------------------\n",
    "# Generic Agent Function (LLM Call)\n",
    "# --------------------------------------\n",
    "def run_agent(agent_name: str, query_text: str, model: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls the LLM API for a given agent and updates the database with its response.\n",
    "    \"\"\"\n",
    "    print(f\"🤖 {agent_name} ({model}) is handling this query...\")\n",
    "    full_prompt = f\"System: {SYSTEM_PROMPT}\\nUser: {query_text}\\nAssistant:\"\n",
    "    payload = {\"model\": model, \"prompt\": full_prompt, \"stream\": False}\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            raw_response = response.json()\n",
    "            print(f\"🔍 Raw LLM Response ({agent_name}):\", raw_response)\n",
    "            answer = raw_response.get(\"response\", \"\").strip()\n",
    "            answer = clean_response(answer)\n",
    "            if len(answer) > 350:\n",
    "                answer = answer[:350] + \"...\"\n",
    "            print(f\"📝 {agent_name} Response: {answer}\")\n",
    "            if answer:\n",
    "                update_generated_response(agent_name, answer)\n",
    "            else:\n",
    "                print(f\"⚠️ Received an empty response from {agent_name} LLM.\")\n",
    "            return answer if answer else \"No valid response received.\"\n",
    "        else:\n",
    "            print(f\"❌ HTTP Error ({agent_name}): {response.status_code} - {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {agent_name} request failed: {str(e)}\")\n",
    "    return \"No valid response received.\"\n",
    "\n",
    "# --------------------------------------\n",
    "# Individual Agent Functions (Wrappers)\n",
    "# --------------------------------------\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def run_cot_langchain(query_text: str, model: str) -> str:\n",
    "    return run_agent(\"Chain of Thought (CoT)\", query_text, model)\n",
    "\n",
    "def run_zero_shot_cot(query_text: str, model: str) -> str:\n",
    "    print(f\"🤖 Zero-Shot CoT ({model}) is handling this query with chain-of-thought reasoning (zero-shot)...\")\n",
    "    modified_query = query_text + \" Let's think step by step.\"\n",
    "    return run_agent(\"Zero-Shot CoT\", modified_query, model)\n",
    "\n",
    "def run_reprompting(query_text: str, model: str) -> str:\n",
    "    base_instruction = \"Please provide a detailed, step-by-step reasoning for your answer, verifying each step for correctness.\"\n",
    "    initial_query = query_text + \" \" + base_instruction\n",
    "    answer = run_agent(\"Re-Prompting\", initial_query, model)\n",
    "    if len(answer) < 50 or \"step\" not in answer.lower():\n",
    "        refinement_instruction = \"The previous response did not include enough step-by-step reasoning. Please re-generate your answer by breaking down the problem and validating each step explicitly.\"\n",
    "        refined_query = query_text + \" \" + refinement_instruction\n",
    "        answer = run_agent(\"Re-Prompting\", refined_query, model)\n",
    "    return answer\n",
    "\n",
    "def run_rewoo(query_text: str, model: str) -> str:\n",
    "    candidate_plan = run_agent(\"ReWOO\", query_text, model)\n",
    "    observation = \"Observation: No anomalies detected in the environment.\"\n",
    "    final_response = candidate_plan + \" \" + observation\n",
    "    if len(final_response) > 350:\n",
    "        final_response = final_response[:350] + \"...\"\n",
    "    print(f\"📝 ReWOO Final Response: {final_response}\")\n",
    "    update_generated_response(\"ReWOO\", final_response)\n",
    "    return final_response\n",
    "\n",
    "def run_hugginggpt(query_text: str, model: str) -> str:\n",
    "    decomposition_instruction = (\n",
    "        \" Please decompose the task into a series of sub-tasks. \"\n",
    "        \"For each sub-task, indicate which HuggingFace model would be best suited to solve it, \"\n",
    "        \"and then integrate the outcomes into a final concise answer.\"\n",
    "    )\n",
    "    modified_query = query_text + \" \" + decomposition_instruction\n",
    "    return run_agent(\"HuggingGPT\", modified_query, model)\n",
    "\n",
    "def run_tree_of_thought(query_text: str, model: str) -> str:\n",
    "    print(f\"🤖 Tree-of-Thought (ToT) ({model}) is handling this query...\")\n",
    "    initial_prompt = (\n",
    "        f\"System: {SYSTEM_PROMPT}\\nUser: {query_text}\\nAssistant: \"\n",
    "        \"Generate 3 distinct candidate reasoning steps to approach this problem, \"\n",
    "        \"each on a separate line.\"\n",
    "    )\n",
    "    payload_init = {\"model\": model, \"prompt\": initial_prompt, \"stream\": False}\n",
    "    try:\n",
    "        response_init = requests.post(\"http://localhost:11434/api/generate\", json=payload_init)\n",
    "        if response_init.status_code == 200:\n",
    "            raw_init = response_init.json()\n",
    "            print(\"🔍 Raw initial candidate response (ToT):\", raw_init)\n",
    "            candidate_text = raw_init.get(\"response\", \"\").strip()\n",
    "            candidates = [clean_response(line) for line in candidate_text.split(\"\\n\") if line.strip()]\n",
    "        else:\n",
    "            print(f\"❌ HTTP Error during candidate generation (ToT): {response_init.status_code} - {response_init.text}\")\n",
    "            candidates = []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Candidate generation failed (ToT): {str(e)}\")\n",
    "        candidates = []\n",
    "    if not candidates:\n",
    "        final_response = \"No valid chain of thought generated.\"\n",
    "        update_generated_response(\"Tree-of-Thought (ToT)\", final_response)\n",
    "        return final_response\n",
    "    expanded_candidates = []\n",
    "    for candidate in candidates:\n",
    "        expansion_prompt = (\n",
    "            f\"System: {SYSTEM_PROMPT}\\nUser: Given the candidate reasoning step: '{candidate}', \"\n",
    "            \"please expand it with additional detailed, step-by-step reasoning.\"\n",
    "        )\n",
    "        payload_exp = {\"model\": model, \"prompt\": expansion_prompt, \"stream\": False}\n",
    "        try:\n",
    "            response_exp = requests.post(\"http://localhost:11434/api/generate\", json=payload_exp)\n",
    "            if response_exp.status_code == 200:\n",
    "                raw_exp = response_exp.json()\n",
    "                print(f\"🔍 Raw expansion for candidate '{candidate}':\", raw_exp)\n",
    "                expansion = raw_exp.get(\"response\", \"\").strip()\n",
    "                expansion = clean_response(expansion)\n",
    "            else:\n",
    "                print(f\"❌ HTTP Error during candidate expansion: {response_exp.status_code} - {response_exp.text}\")\n",
    "                expansion = \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Expansion request failed for candidate '{candidate}': {str(e)}\")\n",
    "            expansion = \"\"\n",
    "        full_candidate = candidate + \" \" + expansion\n",
    "        expanded_candidates.append(full_candidate)\n",
    "    best_candidate = max(expanded_candidates, key=len) if expanded_candidates else \"No valid chain of thought generated.\"\n",
    "    if len(best_candidate) > 350:\n",
    "        best_candidate = best_candidate[:350] + \"...\"\n",
    "    print(f\"📝 Tree-of-Thought (ToT) Final Response: {best_candidate}\")\n",
    "    update_generated_response(\"Tree-of-Thought (ToT)\", best_candidate)\n",
    "    return best_candidate\n",
    "\n",
    "def run_llm_planner(query_text: str, model: str) -> str:\n",
    "    print(f\"🤖 LLM-Planner ({model}) is handling the query with few-shot grounded planning...\")\n",
    "    import os, pickle\n",
    "    knn_file = \"knn_set.pkl\"\n",
    "    examples = []\n",
    "    if os.path.exists(knn_file):\n",
    "        try:\n",
    "            with open(knn_file, \"rb\") as f:\n",
    "                examples = pickle.load(f)\n",
    "            print(\"✅ Loaded few-shot examples from knn_set.pkl.\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error loading knn_set.pkl: {str(e)}\")\n",
    "    if not examples:\n",
    "        examples = [\n",
    "            \"Example 1: For planning a delivery route, first identify all delivery points; second, calculate the distances between them; third, determine an optimized route using a traveling salesman algorithm.\",\n",
    "            \"Example 2: For a cooking task, list the required ingredients; then break down the recipe into sequential steps; finally, factor in cooking times and temperatures to schedule the process.\"\n",
    "        ]\n",
    "    header = f\"System: {SYSTEM_PROMPT}\\nBelow are some few-shot examples for planning:\\n\"\n",
    "    few_shot_examples = \"\\n\\n\".join(examples)\n",
    "    query_part = f\"\\n\\nUser: {query_text}\\nAssistant:\"\n",
    "    full_prompt = header + few_shot_examples + query_part\n",
    "    payload = {\"model\": model, \"prompt\": full_prompt, \"stream\": False}\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            raw_response = response.json()\n",
    "            print(\"🔍 Raw LLM Response (LLM-Planner):\", raw_response)\n",
    "            answer = raw_response.get(\"response\", \"\").strip()\n",
    "            answer = clean_response(answer)\n",
    "            if len(answer) > 350:\n",
    "                answer = answer[:350] + \"...\"\n",
    "            print(f\"📝 LLM-Planner Response: {answer}\")\n",
    "            if answer:\n",
    "                update_generated_response(\"LLM-Planner\", answer)\n",
    "            else:\n",
    "                print(\"⚠️ Received an empty response from LLM-Planner LLM.\")\n",
    "            return answer if answer else \"No valid response received.\"\n",
    "        else:\n",
    "            print(f\"❌ HTTP Error (LLM-Planner): {response.status_code} - {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM-Planner request failed: {str(e)}\")\n",
    "    return \"No valid response received.\"\n",
    "\n",
    "def run_react(query_text: str, model: str) -> str:\n",
    "    react_instruction = (\n",
    "        \" Please follow the ReAct protocol: Begin with a 'Thought:' section where you detail your reasoning. \"\n",
    "        \"Then, decide on an 'Action:' to take based on your reasoning. Follow this with an 'Observation:' section \"\n",
    "        \"to note the outcome, and finally provide your final answer. Keep the response concise and within 350 characters.\"\n",
    "    )\n",
    "    modified_query = query_text + \" \" + react_instruction\n",
    "    return run_agent(\"ReAct\", modified_query, model)\n",
    "\n",
    "def run_llm_plus_p(query_text: str, model: str) -> str:\n",
    "    pddl_instruction = (\n",
    "        \" Please translate the above task into a PDDL problem specification, \"\n",
    "        \"simulate solving the problem with an external planner, \"\n",
    "        \"and finally convert the generated plan back into a concise natural language answer.\"\n",
    "    )\n",
    "    modified_query = query_text + \" \" + pddl_instruction\n",
    "    return run_agent(\"LLM+P\", modified_query, model)\n",
    "\n",
    "def run_inner_monologue(query_text: str, model: str) -> str:\n",
    "    inner_monologue_instruction = (\n",
    "        \" Please provide an inner monologue of your reasoning. \"\n",
    "        \"Describe your internal thought process step by step before arriving at your final concise answer.\"\n",
    "    )\n",
    "    modified_query = query_text + \" \" + inner_monologue_instruction\n",
    "    return run_agent(\"Inner Monologue\", modified_query, model)\n",
    "\n",
    "def run_llm4rl(query_text: str, model: str) -> str:\n",
    "    rl_instruction = (\n",
    "        \" Please generate an initial candidate plan for the above task. Then, simulate evaluating this plan \"\n",
    "        \"using a reinforcement learning signal, and iteratively refine it to maximize the expected reward. \"\n",
    "        \"Finally, output the refined plan in a concise format.\"\n",
    "    )\n",
    "    modified_query = query_text + \" \" + rl_instruction\n",
    "    return run_agent(\"LLM4RL\", modified_query, model)\n",
    "\n",
    "def run_chatcot(query_text: str, model: str) -> str:\n",
    "    feedback_instruction = (\n",
    "        \" First, generate a detailed chain-of-thought reasoning for the query. \"\n",
    "        \"Then, reflect on your reasoning by checking each step for correctness. \"\n",
    "        \"Finally, summarize your thought process and provide a concise final answer.\"\n",
    "    )\n",
    "    full_prompt = f\"System: {SYSTEM_PROMPT}\\nUser: {query_text} {feedback_instruction}\\nAssistant:\"\n",
    "    payload = {\"model\": model, \"prompt\": full_prompt, \"stream\": False}\n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            raw_response = response.json()\n",
    "            print(\"🔍 Raw LLM Response (ChatCoT):\", raw_response)\n",
    "            answer = raw_response.get(\"response\", \"\").strip()\n",
    "            answer = clean_response(answer)\n",
    "            if len(answer) > 350:\n",
    "                answer = answer[:350] + \"...\"\n",
    "            print(f\"📝 ChatCoT Response: {answer}\")\n",
    "            if answer:\n",
    "                update_generated_response(\"ChatCoT\", answer)\n",
    "            else:\n",
    "                print(\"⚠️ Received an empty response from ChatCoT LLM.\")\n",
    "            return answer if answer else \"No valid response received.\"\n",
    "        else:\n",
    "            print(f\"❌ HTTP Error (ChatCoT): {response.status_code} - {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ChatCoT request failed: {str(e)}\")\n",
    "    return \"No valid response received.\"\n",
    "\n",
    "def run_tptu(query_text: str, model: str) -> str:\n",
    "    tptu_instruction = (\n",
    "        \" Please first provide an initial draft answer to the above query. Then, simulate receiving feedback \"\n",
    "        \"from a human advisor on your draft answer, and iteratively refine your response based on that feedback. \"\n",
    "        \"Finally, output your refined final answer in a concise manner.\"\n",
    "    )\n",
    "    modified_query = query_text + \" \" + tptu_instruction\n",
    "    return run_agent(\"TPTU\", modified_query, model)\n",
    "\n",
    "def run_self_refine(query_text: str, model: str) -> str:\n",
    "    print(\"🔹 Self-Refine: Generating initial answer...\")\n",
    "    initial_answer = run_agent(\"Self-Refine\", query_text, model)\n",
    "    refinement_instruction = (\n",
    "        \" Please review the initial answer provided above, and refine it to improve clarity, correctness, \"\n",
    "        \"and conciseness. Ensure that the final answer is accurate and well-formulated.\"\n",
    "    )\n",
    "    refinement_query = query_text + \" Initial Answer: \" + initial_answer + \" \" + refinement_instruction\n",
    "    print(\"🔹 Self-Refine: Generating refined answer...\")\n",
    "    refined_answer = run_agent(\"Self-Refine\", refinement_query, model)\n",
    "    return refined_answer\n",
    "\n",
    "def run_selfcheck(query_text: str, model: str) -> str:\n",
    "    print(\"🔹 SelfCheck: Generating initial answer...\")\n",
    "    initial_answer = run_agent(\"SelfCheck\", query_text, model)\n",
    "    print(\"🔹 SelfCheck: Reviewing the initial answer for errors...\")\n",
    "    selfcheck_instruction = (\n",
    "        \" Please review the initial answer provided above. \"\n",
    "        \"Identify any errors, inconsistencies, or areas that require clarification. \"\n",
    "        \"Then, generate a final corrected answer. \"\n",
    "        \"If the initial answer is already accurate, confirm its correctness.\"\n",
    "    )\n",
    "    selfcheck_query = query_text + \" Initial Answer: \" + initial_answer + \" \" + selfcheck_instruction\n",
    "    final_answer = run_agent(\"SelfCheck\", selfcheck_query, model)\n",
    "    return final_answer\n",
    "\n",
    "# --------------------------------------\n",
    "# Process Agents: Run All and Store Responses\n",
    "# --------------------------------------\n",
    "def process_agents(query_text: str, model: str):\n",
    "    \"\"\"Runs all planning agent functions and stores responses.\"\"\"\n",
    "    setup_database()\n",
    "    populate_planning_taxonomy()\n",
    "    \n",
    "    agent_functions = {\n",
    "        \"Chain of Thought (CoT)\": run_cot_langchain,\n",
    "        \"Zero-Shot CoT\": run_zero_shot_cot,\n",
    "        \"Re-Prompting\": run_reprompting,\n",
    "        \"ReWOO\": run_rewoo,\n",
    "        \"HuggingGPT\": run_hugginggpt,\n",
    "        \"Tree-of-Thought (ToT)\": run_tree_of_thought,\n",
    "        \"LLM-Planner\": run_llm_planner,\n",
    "        \"ReAct\": run_react,\n",
    "        \"LLM+P\": run_llm_plus_p,\n",
    "        \"Inner Monologue\": run_inner_monologue,\n",
    "        \"LLM4RL\": run_llm4rl,\n",
    "        \"ChatCoT\": run_chatcot,\n",
    "        \"TPTU\": run_tptu,\n",
    "        \"Self-Refine\": run_self_refine,\n",
    "        \"SelfCheck\": run_selfcheck,\n",
    "    }\n",
    "    responses = {}\n",
    "    \n",
    "    for agent_name, func in agent_functions.items():\n",
    "        print(f\"\\n🔹 Processing {agent_name}...\")\n",
    "        response = func(query_text, model)\n",
    "        responses[agent_name] = response if response else \"No valid response received.\"\n",
    "    \n",
    "    for agent_name, response in responses.items():\n",
    "        store_agent_response(agent_name, response)\n",
    "    \n",
    "    print(\"\\n✅ Responses stored for all agents.\")\n",
    "    for agent_name, response in responses.items():\n",
    "        print(f\"✅ {agent_name} Response: {response}\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Semantic Search Functionality Using FAISS\n",
    "# --------------------------------------\n",
    "def semantic_search_responses(query: str, top_k: int = 3, embed_model_name: str = \"all-MiniLM-L6-v2\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Fetches all generated responses from the agents table, encodes them using SentenceTransformer,\n",
    "    builds a FAISS index, and returns the top_k responses most similar to the query.\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        df = pd.read_sql(\"SELECT title, generated_response FROM agents\", conn)\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"generated_response\"]:\n",
    "            responses.extend(row[\"generated_response\"])\n",
    "    if not responses:\n",
    "        print(\"No responses found in the database.\")\n",
    "        return []\n",
    "    embed_model = SentenceTransformer(embed_model_name)\n",
    "    response_embeddings = embed_model.encode(responses, convert_to_numpy=True)\n",
    "    d = response_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(response_embeddings)\n",
    "    query_embedding = embed_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    top_responses = [responses[i] for i in indices[0]]\n",
    "    return top_responses\n",
    "\n",
    "# --------------------------------------\n",
    "# Main Function (Entry Point)\n",
    "# --------------------------------------\n",
    "def main():\n",
    "    model = \"tinyllama\"  # Using tinyllama for all agents\n",
    "    query_text = \"Provide a brief overview of quantum computing.\"\n",
    "    csv_filepath = \"agents.csv\"  # Ensure this CSV exists and contains agent rows\n",
    "    \n",
    "    drop_existing_table()        # Drop all existing tables for a clean slate\n",
    "    setup_database()             # Create new tables\n",
    "    populate_planning_taxonomy() # Populate planning_categories and planning_subcategories\n",
    "    insert_agents_from_csv(csv_filepath)  # Insert agents from CSV\n",
    "    print(\"✅ Data insertion completed.\")\n",
    "    \n",
    "    process_agents(query_text, model)\n",
    "    \n",
    "    search_query = \"Which aspects of quantum computing are mentioned?\"\n",
    "    top_responses = semantic_search_responses(search_query, top_k=3)\n",
    "    print(\"\\n✅ Top responses from semantic search:\")\n",
    "    for res in top_responses:\n",
    "        print(res)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# =====================================\n",
    "# 🔹 PostgreSQL Connection (New Project DB)\n",
    "# =====================================\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",           # New project database\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",     # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Load SentenceTransformer Model for Vector Encoding\n",
    "# =====================================\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Step 1: Retrieve & Process Responses from PostgreSQL\n",
    "# =====================================\n",
    "# Here, we unnest the generated_response array from the agents table.\n",
    "# Adjust the WHERE clause if you want to select a different set of agents.\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "query = \"\"\"\n",
    "SELECT title, t.response, t.idx\n",
    "FROM agents\n",
    "CROSS JOIN LATERAL unnest(generated_response) WITH ORDINALITY AS t(response, idx)\n",
    "WHERE title IN ('SmolAgents', 'AutoGen', 'Reflexion', 'ChatCoT', 'Chain of Thought (CoT)', 'Zero-Shot CoT', 'Re-Prompting', 'ReWOO', 'HuggingGPT', 'Tree-of-Thought (ToT)', 'LLM-Planner', 'ReAct', 'LLM+P', 'Inner Monologue', 'LLM4RL', 'TPTU', 'Self-Refine', 'SelfCheck')\n",
    "ORDER BY t.idx;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Step 2: Group Responses by Ordinality (Index)\n",
    "# =====================================\n",
    "# Each unnest index (idx) represents a particular \"batch\" or task iteration.\n",
    "grouped_responses = defaultdict(dict)  # Dictionary mapping index -> {agent_title: response}\n",
    "for _, row in df.iterrows():\n",
    "    # Group responses by the ordinal index 'idx'\n",
    "    grouped_responses[row['idx']][row['title']] = row['response']\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Step 3: Convert Text Responses to Vectors & Store in FAISS Indexes\n",
    "# =====================================\n",
    "# We'll create a separate FAISS index for each vector space (i.e. each idx).\n",
    "faiss_indexes = {}  # Dictionary mapping idx -> FAISS index\n",
    "for idx, response_dict in grouped_responses.items():\n",
    "    print(f\"\\n🔹 Processing Vector Space (idx) {idx}...\")\n",
    "    agent_names = list(response_dict.keys())\n",
    "    responses = list(response_dict.values())\n",
    "    # Skip vector spaces with fewer than 2 responses (cannot compare if only one exists)\n",
    "    if len(responses) < 2:\n",
    "        print(f\"⚠️ Skipping Vector Space {idx} - Not enough responses.\")\n",
    "        continue\n",
    "    # Convert text responses to embeddings using the SentenceTransformer model.\n",
    "    embeddings = embed_model.encode(responses, convert_to_numpy=True)\n",
    "    # 'dimension' is the size of each embedding vector.\n",
    "    dimension = embeddings.shape[1]\n",
    "    if idx not in faiss_indexes:\n",
    "        faiss_indexes[idx] = faiss.IndexFlatL2(dimension)\n",
    "    # Add vectors to the FAISS index.\n",
    "    if faiss_indexes[idx].ntotal == 0:\n",
    "        faiss_indexes[idx].add(np.array(embeddings, dtype=np.float32))\n",
    "        print(f\"✅ Stored {len(responses)} responses in Vector Space {idx}\")\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Step 4: Similarity Computation and Convergence Assessment\n",
    "# =====================================\n",
    "def check_stability(euclidean_distance, cos_sim, agent_pair, vector_space_id):\n",
    "    \"\"\"\n",
    "    Determines if the agents are converging (Stable), diverging (Need Human Feedback), or partially in agreement (Mixed).\n",
    "    THRESHOLD NOTE: Adjust these threshold values later based on empirical results.\n",
    "    \"\"\"\n",
    "    if euclidean_distance < 0.3 and cos_sim > 0.9:\n",
    "        status = f\"✅ {agent_pair} are converging (Stable)\"\n",
    "    elif euclidean_distance > 1.0 and cos_sim < 0.5:\n",
    "        status = f\"❌ {agent_pair} are diverging (Need Human Feedback)\"\n",
    "    else:\n",
    "        status = f\"🔄 {agent_pair} have partial agreement (Mixed)\"\n",
    "    \n",
    "    print(f\"🔹 Stability Status for {agent_pair} in Vector Space {vector_space_id}: {status}\\n\")\n",
    "\n",
    "def compute_similarity(vector_space_id):\n",
    "    \"\"\"\n",
    "    Computes both Euclidean Distance and Cosine Similarity between responses from different agents\n",
    "    in a given vector space (identified by idx).\n",
    "    \"\"\"\n",
    "    if vector_space_id not in faiss_indexes:\n",
    "        print(f\"⚠️ No FAISS index found for Vector Space {vector_space_id}.\")\n",
    "        return\n",
    "    index = faiss_indexes[vector_space_id]\n",
    "    num_vectors = index.ntotal\n",
    "    if num_vectors < 2:\n",
    "        print(f\"⚠️ Not enough responses in Vector Space {vector_space_id} to compute similarity.\")\n",
    "        return\n",
    "    print(f\"🔍 Computing similarity for Vector Space {vector_space_id}...\")\n",
    "    # Retrieve stored vectors from the FAISS index.\n",
    "    stored_vectors = np.zeros((num_vectors, index.d), dtype=np.float32)\n",
    "    for i in range(num_vectors):\n",
    "        index.reconstruct(i, stored_vectors[i])\n",
    "    # Dynamically map agent names to their vectors.\n",
    "    agent_names = list(grouped_responses[vector_space_id].keys())\n",
    "    vector_map = {agent_names[i]: stored_vectors[i] for i in range(num_vectors)}\n",
    "    # Compute pairwise similarities for each unique agent pair.\n",
    "    agent_pairs = [(a, b) for i, a in enumerate(agent_names) for b in agent_names[i+1:]]\n",
    "    for agent_a, agent_b in agent_pairs:\n",
    "        v1, v2 = vector_map[agent_a], vector_map[agent_b]\n",
    "        euclidean_distance = np.linalg.norm(v1 - v2)\n",
    "        cos_sim = cosine_similarity([v1], [v2])[0][0]\n",
    "        print(f\"✅ Euclidean Distance ({agent_a} ↔ {agent_b}): {euclidean_distance:.4f}\")\n",
    "        print(f\"✅ Cosine Similarity ({agent_a} ↔ {agent_b}): {cos_sim:.4f}\")\n",
    "        check_stability(euclidean_distance, cos_sim, f\"{agent_a} ↔ {agent_b}\", vector_space_id)\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Step 5: Run Similarity Computation for Each Vector Space\n",
    "# =====================================\n",
    "for vector_space_id in grouped_responses.keys():\n",
    "    compute_similarity(vector_space_id)\n",
    "print(\"\\n🚀 All vector spaces processed successfully!\")\n",
    "\n",
    "# =====================================\n",
    "# 🔹 New Step: Compute Task Performance Metrics and Save to Database\n",
    "# =====================================\n",
    "def compute_task_performance(vector_space_id):\n",
    "    \"\"\"\n",
    "    Computes overall performance metrics for a given vector space (task iteration):\n",
    "      - Average Euclidean distance (avg_euclidean_distance)\n",
    "      - Average cosine similarity (avg_cosine_similarity)\n",
    "      - Evaluation score (evaluation_score) as the sum of the above averages (placeholder)\n",
    "      - Average response length (response_length)\n",
    "      - Completion time (completion_time) for processing this vector space.\n",
    "    Note: Thresholds and evaluation formula might need adjustment.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    if vector_space_id not in faiss_indexes:\n",
    "        print(f\"⚠️ No FAISS index for Vector Space {vector_space_id}.\")\n",
    "        return None\n",
    "    index = faiss_indexes[vector_space_id]\n",
    "    num_vectors = index.ntotal\n",
    "    if num_vectors < 2:\n",
    "        print(f\"⚠️ Not enough responses in Vector Space {vector_space_id} for performance computation.\")\n",
    "        return None\n",
    "    # Reconstruct stored vectors.\n",
    "    stored_vectors = np.zeros((num_vectors, index.d), dtype=np.float32)\n",
    "    for i in range(num_vectors):\n",
    "        index.reconstruct(i, stored_vectors[i])\n",
    "    # Compute response lengths.\n",
    "    responses = list(grouped_responses[vector_space_id].values())\n",
    "    response_lengths = [len(r) for r in responses]\n",
    "    # Compute pairwise distances and cosine similarities.\n",
    "    distances = []\n",
    "    cosine_sims = []\n",
    "    for i in range(num_vectors):\n",
    "        for j in range(i+1, num_vectors):\n",
    "            d = np.linalg.norm(stored_vectors[i] - stored_vectors[j])\n",
    "            cs = cosine_similarity([stored_vectors[i]], [stored_vectors[j]])[0][0]\n",
    "            distances.append(d)\n",
    "            cosine_sims.append(cs)\n",
    "    if distances and cosine_sims:\n",
    "        avg_distance = np.mean(distances)\n",
    "        avg_cos_sim = np.mean(cosine_sims)\n",
    "    else:\n",
    "        avg_distance = avg_cos_sim = 0\n",
    "    avg_response_length = np.mean(response_lengths) if response_lengths else 0\n",
    "    completion_time = time.time() - start_time\n",
    "    return {\n",
    "        \"avg_euclidean_distance\": avg_distance,\n",
    "        \"avg_cosine_similarity\": avg_cos_sim,\n",
    "        \"response_length\": avg_response_length,\n",
    "        \"completion_time\": completion_time\n",
    "    }\n",
    "\n",
    "def save_task_performance(task_name, performance):\n",
    "    \"\"\"\n",
    "    Saves the computed performance metrics into the task_performance table.\n",
    "    The task_name is typically the ordinal index (converted to string) for this vector space.\n",
    "    \"\"\"\n",
    "    insert_sql = \"\"\"\n",
    "    INSERT INTO task_performance \n",
    "      (task_name, avg_euclidean_distance, avg_cosine_similarity, , response_length, completion_time)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (task_name)\n",
    "    DO UPDATE SET\n",
    "      avg_euclidean_distance = EXCLUDED.avg_euclidean_distance,\n",
    "      avg_cosine_similarity = EXCLUDED.avg_cosine_similarity,\n",
    "      response_length = EXCLUDED.response_length,\n",
    "      completion_time = EXCLUDED.completion_time;\n",
    "    \"\"\"\n",
    "    params = (\n",
    "        task_name,\n",
    "        float(performance[\"avg_euclidean_distance\"]),\n",
    "        float(performance[\"avg_cosine_similarity\"]),\n",
    "        float(performance[\"response_length\"]),\n",
    "        float(performance[\"completion_time\"]) if performance[\"completion_time\"] is not None else None\n",
    "    )\n",
    "    # Print the SQL and parameters for debugging\n",
    "    print(\"Executing SQL:\")\n",
    "    print(insert_sql)\n",
    "    print(\"With parameters:\")\n",
    "    print(params)\n",
    "    \n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        df_perf = pd.read_sql(\"SELECT * FROM task_performance ORDER BY task_name;\", conn)\n",
    "    print(\"Stored task performance records:\")\n",
    "    print(df_perf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each vector space and save performance metrics.\n",
    "for vector_space_id in grouped_responses.keys():\n",
    "    performance = compute_task_performance(vector_space_id)\n",
    "    if performance is not None:\n",
    "        # Here, we use the vector_space_id as the task_name.\n",
    "        save_task_performance(str(vector_space_id), performance)\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Additional: Fetch and Clean Data from the Database\n",
    "# =====================================\n",
    "def fetch_and_clean_responses():\n",
    "    \"\"\"\n",
    "    Fetches responses from the agents table and removes empty responses.\n",
    "    Saves the cleaned data to a CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The cleaned responses DataFrame.\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    query = \"\"\"\n",
    "    SELECT title, t.response, t.idx, profile, memory, action,\n",
    "           capability_acquisition, social_science, natural_science, engineering, benchmark\n",
    "    FROM agents\n",
    "    CROSS JOIN LATERAL unnest(generated_response) WITH ORDINALITY AS t(response, idx)\n",
    "    ORDER BY t.idx;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    # Remove rows with empty or NaN responses.\n",
    "    df_filtered = df[df[\"response\"].notna() & (df[\"response\"].str.strip() != \"\")]\n",
    "    print(f\"\\n✅ Original Data: {df.shape[0]} rows\")\n",
    "    print(f\"✅ Cleaned Data: {df_filtered.shape[0]} rows (Removed {df.shape[0] - df_filtered.shape[0]} empty responses)\\n\")\n",
    "    # Optionally, save cleaned responses to CSV.\n",
    "    df_filtered.to_csv(\"cleaned_agent_responses.csv\", index=False)\n",
    "    print(\"✅ Cleaned responses saved as 'cleaned_agent_responses.csv'.\")\n",
    "    return df_filtered\n",
    "\n",
    "# Execute the cleaning function\n",
    "cleaned_df = fetch_and_clean_responses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# PostgreSQL connection config\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def fetch_task_responses():\n",
    "    \"\"\"\n",
    "    Retrieve generated responses from the agents table, unnesting the generated_response array.\n",
    "    \"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        query = \"\"\"\n",
    "        SELECT title, t.response, t.idx\n",
    "        FROM agents\n",
    "        CROSS JOIN LATERAL unnest(generated_response) WITH ORDINALITY AS t(response, idx)\n",
    "        ORDER BY t.idx;\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "    return df\n",
    "\n",
    "df = fetch_task_responses()\n",
    "print(\"✅ Data Fetched Successfully!\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 🔹 3) Group Responses by Task (Index)\n",
    "# ===============================\n",
    "grouped_responses = defaultdict(dict)  # { idx -> { agent_title: response } }\n",
    "for _, row in df.iterrows():\n",
    "    grouped_responses[row['idx']][row['title']] = row['response']\n",
    "\n",
    "# ===============================\n",
    "# 🔹 4) Global Encoding: PCA & Normalization\n",
    "# ===============================\n",
    "# Extract all responses into a list\n",
    "all_responses = df[\"response\"].tolist()\n",
    "\n",
    "# Convert them to embeddings\n",
    "all_embeddings = embed_model.encode(all_responses, convert_to_numpy=True)\n",
    "\n",
    "# Optional global minmax scaling\n",
    "scaler_global = MinMaxScaler()\n",
    "all_embeddings_scaled = scaler_global.fit_transform(all_embeddings)\n",
    "\n",
    "# PCA to reduce to 2D\n",
    "pca_n_components = min(2, all_embeddings_scaled.shape[1])\n",
    "pca = PCA(n_components=pca_n_components)\n",
    "pca.fit(all_embeddings_scaled)\n",
    "\n",
    "pca_embeddings = pca.transform(all_embeddings_scaled)\n",
    "\n",
    "# (Optional) Another minmax scale after PCA\n",
    "scaler_pca = MinMaxScaler()\n",
    "pca_embeddings_scaled = scaler_pca.fit_transform(pca_embeddings)\n",
    "\n",
    "# ===============================\n",
    "# 🔹 5) Compute Task Rankings Using Fixed PCA - task_matrix = task_titles and task_responses\n",
    "# ===============================\n",
    "# We'll build a task matrix that stores, for each task (idx) and each agent,\n",
    "# a \"Reduced Vector\" (the PCA embedding) and a \"Total Score\" computed as the sum of the absolute values.\n",
    "task_matrix = defaultdict(dict)\n",
    "unique_tasks = df[\"idx\"].unique()\n",
    "\n",
    "for task_id in unique_tasks:\n",
    "    # Subset to this task\n",
    "    task_data = df[df[\"idx\"] == task_id]\n",
    "    task_titles = task_data[\"title\"].tolist()\n",
    "    task_responses = task_data[\"response\"].tolist()\n",
    "\n",
    "    # Indices in the all_responses list\n",
    "    response_indices = [all_responses.index(resp) for resp in task_responses]\n",
    "    reduced_vectors = pca_embeddings_scaled[response_indices]\n",
    "\n",
    "    print(f\"\\n🔹 Task {task_id}: PCA Output Shape = {reduced_vectors.shape}\")\n",
    "\n",
    "    for i, title in enumerate(task_titles):\n",
    "        if i >= len(reduced_vectors):\n",
    "            continue\n",
    "        vector = reduced_vectors[i]\n",
    "\n",
    "        # For demonstration, total_score = sum(abs(vector))\n",
    "        total_score = np.sum(np.abs(vector))\n",
    "\n",
    "        task_matrix[task_id][title] = {\n",
    "            \"Total Score\": total_score,\n",
    "            \"Reduced Vector\": vector\n",
    "        }\n",
    "\n",
    "# (Optional) Remove zero vectors\n",
    "for tid in list(task_matrix.keys()):\n",
    "    for agent in list(task_matrix[tid].keys()):\n",
    "        if np.all(task_matrix[tid][agent][\"Reduced Vector\"] == 0):\n",
    "            del task_matrix[tid][agent]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 🔹 6) Save Task Matrix to CSV\n",
    "# ===============================\n",
    "task_matrix_df = pd.DataFrame.from_dict(\n",
    "    {(t, agent): task_matrix[t][agent] \n",
    "     for t in task_matrix.keys() for agent in task_matrix[t].keys()},\n",
    "    orient='index'\n",
    ").reset_index()\n",
    "task_matrix_df.rename(columns={\"level_0\": \"Task\", \"level_1\": \"Agent\"}, inplace=True)\n",
    "task_matrix_df.to_csv(\"normalized_task_matrix_fixed.csv\", index=False)\n",
    "print(\"✅ Task Matrix CSV saved.\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 🔹 7) Compute Cosine Similarity & Euclidean Distance & Plot Heatmap\n",
    "# ===============================\n",
    "print(\"\\n🔹 Computing Cosine Similarity Between Agents...\\n\")\n",
    "valid_vectors = []\n",
    "valid_agents = []\n",
    "\n",
    "for task_id in sorted(task_matrix.keys()):\n",
    "    for agent in sorted(task_matrix[task_id].keys()):\n",
    "        vector = task_matrix[task_id][agent].get(\"Reduced Vector\", None)\n",
    "        if vector is not None and np.any(vector):\n",
    "            valid_agents.append(f\"{agent} (Task {task_id})\")\n",
    "            valid_vectors.append(vector)\n",
    "            print(f\"  ✅ {agent} (Task {task_id}): Vector Sum = {np.sum(vector):.4f}\")\n",
    "        else:\n",
    "            print(f\"  ❌ {agent} (Task {task_id}): No valid response\")\n",
    "\n",
    "if len(valid_agents) < 2:\n",
    "    print(\"\\n⚠️ Not enough valid responses to compute similarity. At least 2 are required.\")\n",
    "else:\n",
    "    valid_vectors = np.array(valid_vectors)\n",
    "    similarity_matrix = cosine_similarity(valid_vectors)\n",
    "\n",
    "    num_agents = len(valid_agents)\n",
    "    plt.figure(figsize=(min(15, num_agents / 2), min(12, num_agents / 2)))\n",
    "    sns.heatmap(\n",
    "        similarity_matrix,\n",
    "        annot=False,\n",
    "        cmap=\"coolwarm\",\n",
    "        xticklabels=valid_agents if num_agents < 40 else valid_agents[::2],\n",
    "        yticklabels=valid_agents if num_agents < 40 else valid_agents[::2]\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(\"Cosine Similarity Between Agents (PCA-Reduced Features)\")\n",
    "    plt.show()\n",
    "\n",
    "# After your cosine similarity block, add:\n",
    "\n",
    "if len(valid_agents) < 2:\n",
    "    print(\"\\n⚠️ Not enough valid responses to compute Euclidean distances. At least 2 are required.\")\n",
    "else:\n",
    "    # Compute Euclidean distance matrix using broadcasting:\n",
    "    euclidean_matrix = np.sqrt(((valid_vectors[:, np.newaxis] - valid_vectors) ** 2).sum(axis=2))\n",
    "    \n",
    "    # Print the Euclidean matrix for inspection\n",
    "    print(\"Euclidean Distance Matrix:\")\n",
    "    print(euclidean_matrix)\n",
    "    \n",
    "    # Plot the Euclidean distance matrix as a heatmap.\n",
    "    plt.figure(figsize=(min(15, num_agents / 2), min(12, num_agents / 2)))\n",
    "    sns.heatmap(\n",
    "        euclidean_matrix,\n",
    "        annot=True,  # Set to True to display distance values on the heatmap\n",
    "        cmap=\"viridis\",  # You can choose another colormap if preferred\n",
    "        xticklabels=valid_agents if num_agents < 40 else valid_agents[::2],\n",
    "        yticklabels=valid_agents if num_agents < 40 else valid_agents[::2]\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(\"Euclidean Distance Between Agents (PCA-Reduced Features)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 🔹 6) Compute Pair Performance\n",
    "# ===============================\n",
    "def compute_pair_performance(vector1, vector2, response1, response2):\n",
    "    \"\"\"\n",
    "    Computes performance metrics for a pair of responses:\n",
    "      - euclidean_distance: L2 norm between the two vectors.\n",
    "      - cosine_similarity: Cosine similarity between the two vectors.\n",
    "      - evaluation_score: Sum of the two metrics (placeholder; adjust as needed).\n",
    "      - response_length: Average length of the two responses.\n",
    "      - completion_time: Time taken to compute these metrics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    euclidean_distance = np.linalg.norm(vector1 - vector2)\n",
    "    cos_sim = cosine_similarity([vector1], [vector2])[0][0]\n",
    "    evaluation_score = euclidean_distance + cos_sim  # Placeholder formula\n",
    "    avg_response_length = (len(response1) + len(response2)) / 2.0\n",
    "    completion_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        \"euclidean_distance\": float(euclidean_distance),\n",
    "        \"cosine_similarity\": float(cos_sim),\n",
    "        \"evaluation_score\": float(evaluation_score),\n",
    "        \"response_length\": float(avg_response_length),\n",
    "        \"completion_time\": completion_time\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# 🔹 Save Agent Pair Performance\n",
    "# ===============================\n",
    "def save_pair_performance(task_name, agent1, agent2, performance):\n",
    "    \"\"\"\n",
    "    Saves performance metrics for an agent pair into the agent_pair_performance table.\n",
    "    Assumes that (task_name, agent1, agent2) is unique.\n",
    "    \"\"\"\n",
    "    insert_sql = \"\"\"\n",
    "    INSERT INTO agent_pair_performance\n",
    "      (task_name, agent1, agent2, euclidean_distance, cosine_similarity, evaluation_score, response_length, completion_time)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (task_name, agent1, agent2)\n",
    "    DO UPDATE SET\n",
    "      euclidean_distance = EXCLUDED.euclidean_distance,\n",
    "      cosine_similarity = EXCLUDED.cosine_similarity,\n",
    "      evaluation_score = EXCLUDED.evaluation_score,\n",
    "      response_length = EXCLUDED.response_length,\n",
    "      completion_time = EXCLUDED.completion_time;\n",
    "    \"\"\"\n",
    "    params = (\n",
    "        str(task_name),\n",
    "        agent1,\n",
    "        agent2,\n",
    "        performance[\"euclidean_distance\"],\n",
    "        performance[\"cosine_similarity\"],\n",
    "        performance[\"evaluation_score\"],\n",
    "        performance[\"response_length\"],\n",
    "        performance[\"completion_time\"]\n",
    "    )\n",
    "    print(\"Executing SQL:\")\n",
    "    print(insert_sql)\n",
    "    print(\"With parameters:\")\n",
    "    print(params)\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(insert_sql, params)\n",
    "        conn.commit()\n",
    "    print(f\"✅ Saved performance for task {task_name} between {agent1} and {agent2}.\")\n",
    "\n",
    "def process_pair_performance(grouped_responses, task_matrix):\n",
    "    \"\"\"\n",
    "    Loops over each task iteration and for each unique pair of agents in that task,\n",
    "    computes performance metrics and saves them to the agent_pair_performance table.\n",
    "    \"\"\"\n",
    "    for task_id in sorted(grouped_responses.keys()):\n",
    "        responses_dict = grouped_responses[task_id]\n",
    "        agents = list(responses_dict.keys())\n",
    "        # Ensure at least two agents provided a response.\n",
    "        if len(agents) < 2:\n",
    "            continue\n",
    "        for i in range(len(agents)):\n",
    "            for j in range(i + 1, len(agents)):\n",
    "                agent1 = agents[i]\n",
    "                agent2 = agents[j]\n",
    "                if agent1 in task_matrix[task_id] and agent2 in task_matrix[task_id]:\n",
    "                    vector1 = task_matrix[task_id][agent1][\"Reduced Vector\"]\n",
    "                    vector2 = task_matrix[task_id][agent2][\"Reduced Vector\"]\n",
    "                    response1 = responses_dict[agent1]\n",
    "                    response2 = responses_dict[agent2]\n",
    "                    performance = compute_pair_performance(vector1, vector2, response1, response2)\n",
    "                    save_pair_performance(task_id, agent1, agent2, performance)\n",
    "\n",
    "    with psycopg2.connect(**DB_CONFIG, cursor_factory=LoggingCursor) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(insert_sql, params)\n",
    "        conn.commit()\n",
    "    print(f\"✅ Saved performance for task {task_id} between {agent1} and {agent2}.\")\n",
    "\n",
    "# ===============================\n",
    "# 🔹 7) Loop Over Each Task Iteration and Compute Pairwise Performance\n",
    "# ===============================\n",
    "for task_id in sorted(grouped_responses.keys()):\n",
    "    responses_dict = grouped_responses[task_id]  # {agent_title: response}\n",
    "    agents = list(responses_dict.keys())\n",
    "    # Ensure at least two agents provided a response for this task.\n",
    "    if len(agents) < 2:\n",
    "        continue\n",
    "    # Loop over all unique pairs of agents.\n",
    "    for i in range(len(agents)):\n",
    "        for j in range(i + 1, len(agents)):\n",
    "            agent1 = agents[i]\n",
    "            agent2 = agents[j]\n",
    "            # Retrieve PCA-reduced vectors from your task_matrix.\n",
    "            # (Ensure that agent names in task_matrix match those in grouped_responses.)\n",
    "            if agent1 in task_matrix[task_id] and agent2 in task_matrix[task_id]:\n",
    "                vector1 = task_matrix[task_id][agent1][\"Reduced Vector\"]\n",
    "                vector2 = task_matrix[task_id][agent2][\"Reduced Vector\"]\n",
    "                response1 = responses_dict[agent1]\n",
    "                response2 = responses_dict[agent2]\n",
    "                \n",
    "                performance = compute_pair_performance(vector1, vector2, response1, response2)\n",
    "                save_pair_performance(task_id, agent1, agent2, performance)\n",
    "            else:\n",
    "                print(f\"❌ Missing reduced vector for {agent1} or {agent2} in task {task_id}\")\n",
    "\n",
    "# ===============================\n",
    "# 🔹 8) Display Stored Performance Tables\n",
    "# ===============================\n",
    "# Connect to the database and read the agent_pair_performance table into a DataFrame.\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_agent_pair = pd.read_sql(\"SELECT * FROM agent_pair_performance ORDER BY task_name, agent1, agent2;\", conn)\n",
    "\n",
    "print(\"Agent Pair Performance Table:\")\n",
    "print(df_agent_pair)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "planning_categories\n",
    "id\tname\n",
    "1\tPlanning Without Feedback\n",
    "2\tPlanning With Feedback\n",
    "\n",
    "planning_subcategories\n",
    "id\tname\tcategory_id\n",
    "1\tSingle-Path Reasoning\t1\n",
    "2\tMulti-Path Reasoning\t1\n",
    "3\tExternal Planner\t1\n",
    "4\tEnvironment Feedback\t2\n",
    "5\tHuman Feedback\t2\n",
    "6\tModel Feedback\t2\n",
    "\n",
    "id\ttitle\tprofile\tmemory\t...\tgenerated_response\n",
    "1\tChain of Thought (CoT)\tSome profile...\tSome mem\t...\t{ \"The train's speed is 60 km/h\", \"Computed as 120/2\" }\n",
    "2\tZero-Shot CoT\t...\t...\t...\t{ \"Average speed is 60 km/h\" }\n",
    "3\tChatCoT\t...\t...\t...\t{ \"The train travels at 60 km/h.\" }\n",
    "\n",
    "\n",
    "id\ttask_name\tavg_euclidean_distance\tavg_cosine_similarity\tevaluation_score\tresponse_length\tcompletion_time\ttimestamp\n",
    "1\t\"1\"\t0.45\t0.87\t1.32\t120\t0.234\t2024-02-13 12:34:56\n",
    "2\t\"2\"\t0.38\t0.91\t1.29\t105\t0.198\t2024-02-13 12:35:12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Database Connection Config\n",
    "# -------------------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Fetch Data from Database\n",
    "# -------------------------------\n",
    "# Connect to the database and fetch all rows from the agent_pair_performance table.\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_agent_pair = pd.read_sql(\"SELECT * FROM agent_pair_performance ORDER BY task_name, agent1, agent2;\", conn)\n",
    "\n",
    "print(\"Agent Pair Performance Data (first few rows):\")\n",
    "print(df_agent_pair.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Filter Data by Task\n",
    "# -------------------------------\n",
    "# Choose a task to visualize. For example, we use task \"1\".\n",
    "task_id = '1'\n",
    "df_task = df_agent_pair[df_agent_pair['task_name'] == task_id]\n",
    "\n",
    "if df_task.empty:\n",
    "    print(f\"No data found for task {task_id}.\")\n",
    "else:\n",
    "    # -------------------------------\n",
    "    # 4) Pivot Data for Heatmaps\n",
    "    # -------------------------------\n",
    "    # Pivot the table so that rows represent agent1 and columns represent agent2.\n",
    "    euclidean_matrix = df_task.pivot(index='agent1', columns='agent2', values='euclidean_distance')\n",
    "    cosine_matrix = df_task.pivot(index='agent1', columns='agent2', values='cosine_similarity')\n",
    "\n",
    "    print(\"\\nEuclidean Distance Matrix for Task\", task_id)\n",
    "    print(euclidean_matrix)\n",
    "    print(\"\\nCosine Similarity Matrix for Task\", task_id)\n",
    "    print(cosine_matrix)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5) Plot the Heatmaps\n",
    "    # -------------------------------\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(euclidean_matrix, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "    plt.title(f\"Euclidean Distance Matrix for Task {task_id}\")\n",
    "    plt.xlabel(\"Agent 2\")\n",
    "    plt.ylabel(\"Agent 1\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cosine_matrix, annot=True, fmt=\".3f\", cmap=\"coolwarm\")\n",
    "    plt.title(f\"Cosine Similarity Matrix for Task {task_id}\")\n",
    "    plt.xlabel(\"Agent 2\")\n",
    "    plt.ylabel(\"Agent 1\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Database Connection Config\n",
    "# -------------------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Fetch agent_pair_performance Data from DB\n",
    "# -------------------------------\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_pair = pd.read_sql(\"SELECT * FROM agent_pair_performance ORDER BY task_name, agent1, agent2;\", conn)\n",
    "\n",
    "print(\"Agent Pair Performance Data (first few rows):\")\n",
    "print(df_pair.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Prepare Data for Agent-Level Average ED Calculation\n",
    "# -------------------------------\n",
    "# For each pair (agent1, agent2) in a task, we want to assign the ED to both agents.\n",
    "# Duplicate each row for agent1 and agent2.\n",
    "df_agent1 = df_pair[['task_name', 'agent1', 'euclidean_distance']].rename(columns={'agent1': 'agent'})\n",
    "df_agent2 = df_pair[['task_name', 'agent2', 'euclidean_distance']].rename(columns={'agent2': 'agent'})\n",
    "df_agents = pd.concat([df_agent1, df_agent2], ignore_index=True)\n",
    "\n",
    "# Now, group by task_name and agent to compute the average Euclidean distance for that agent.\n",
    "df_avg_ed = df_agents.groupby(['task_name', 'agent'], as_index=False)['euclidean_distance'].mean()\n",
    "df_avg_ed.rename(columns={'euclidean_distance': 'avg_euclidean_distance'}, inplace=True)\n",
    "\n",
    "print(\"\\nAverage Euclidean Distance per Agent per Task:\")\n",
    "print(df_avg_ed.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Pivot Data for Plotting\n",
    "# -------------------------------\n",
    "# Pivot so that rows = task_name and columns = agent names with the average ED as values.\n",
    "df_pivot = df_avg_ed.pivot(index='task_name', columns='agent', values='avg_euclidean_distance')\n",
    "print(\"\\nPivoted Data (tasks x agents):\")\n",
    "print(df_pivot.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Plotting: Scatter Plot of Average ED for Each Agent Across Tasks\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# For each agent (i.e. each column in the pivoted DataFrame), plot its average ED across tasks.\n",
    "for agent in df_pivot.columns:\n",
    "    # Drop tasks where the agent does not have a value\n",
    "    task_vals = df_pivot[agent].dropna()\n",
    "    plt.scatter(task_vals.index, task_vals.values, label=agent, s=100, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Task Name')\n",
    "plt.ylabel('Average Euclidean Distance')\n",
    "plt.title('Average Euclidean Distance per Agent Across Tasks')\n",
    "plt.legend(title=\"Agent\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Database Connection Config\n",
    "# -------------------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Fetch agent_pair_performance Data from DB\n",
    "# -------------------------------\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_pair = pd.read_sql(\"SELECT * FROM agent_pair_performance ORDER BY task_name, agent1, agent2;\", conn)\n",
    "\n",
    "print(\"Agent Pair Performance Data (first few rows):\")\n",
    "print(df_pair.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Prepare Data for Agent-Level Average Cosine Similarity Calculation\n",
    "# -------------------------------\n",
    "# Duplicate each row so that both agent1 and agent2 get the cosine similarity value.\n",
    "df_agent1 = df_pair[['task_name', 'agent1', 'cosine_similarity']].rename(columns={'agent1': 'agent'})\n",
    "df_agent2 = df_pair[['task_name', 'agent2', 'cosine_similarity']].rename(columns={'agent2': 'agent'})\n",
    "df_agents = pd.concat([df_agent1, df_agent2], ignore_index=True)\n",
    "\n",
    "# Group by task_name and agent, computing the mean cosine similarity for each agent.\n",
    "df_avg_cosine = df_agents.groupby(['task_name', 'agent'], as_index=False)['cosine_similarity'].mean()\n",
    "df_avg_cosine.rename(columns={'cosine_similarity': 'avg_cosine_similarity'}, inplace=True)\n",
    "\n",
    "print(\"\\nAverage Cosine Similarity per Agent per Task:\")\n",
    "print(df_avg_cosine.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Pivot Data for Plotting\n",
    "# -------------------------------\n",
    "# Pivot the data so that each row is a task and each column is an agent.\n",
    "df_pivot_cosine = df_avg_cosine.pivot(index='task_name', columns='agent', values='avg_cosine_similarity')\n",
    "print(\"\\nPivoted Data (tasks x agents) for Cosine Similarity:\")\n",
    "print(df_pivot_cosine.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Plotting: Scatter Plot of Average Cosine Similarity for Each Agent Across Tasks\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "for agent in df_pivot_cosine.columns:\n",
    "    # Drop tasks where the agent does not have a value\n",
    "    task_vals = df_pivot_cosine[agent].dropna()\n",
    "    plt.scatter(task_vals.index, task_vals.values, label=agent, s=100, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Task Name')\n",
    "plt.ylabel('Average Cosine Similarity')\n",
    "plt.title('Average Cosine Similarity per Agent Across Tasks')\n",
    "plt.legend(title=\"Agent\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Database Connection Config\n",
    "# -------------------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Fetch Task 1 Agent Pair Performance Data\n",
    "# -------------------------------\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_task1 = pd.read_sql(\"SELECT * FROM agent_pair_performance WHERE task_name = '1';\", conn)\n",
    "\n",
    "print(\"Task 1 Agent Pair Performance Data:\")\n",
    "print(df_task1.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Prepare Features for Clustering (excluding evaluation_score)\n",
    "# -------------------------------\n",
    "# Use the remaining performance metrics as features.\n",
    "features = ['euclidean_distance', 'cosine_similarity', 'response_length', 'completion_time']\n",
    "X = df_task1[features].values\n",
    "\n",
    "# Scale the features so that each metric contributes equally.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Perform KMeans Clustering\n",
    "# -------------------------------\n",
    "# Choose the number of clusters; for example, k=3.\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df_task1['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(\"\\nCluster assignments:\")\n",
    "print(df_task1[['task_name', 'agent1', 'agent2', 'cluster']])\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Dimensionality Reduction with PCA for Visualization\n",
    "# -------------------------------\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df_task1['pca1'] = X_pca[:, 0]\n",
    "df_task1['pca2'] = X_pca[:, 1]\n",
    "\n",
    "# -------------------------------\n",
    "# 6) Plot the Clustering Results\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_task1, x='pca1', y='pca2', hue='cluster', palette='viridis', s=100)\n",
    "\n",
    "# Annotate each point with the agent pair names.\n",
    "for idx, row in df_task1.iterrows():\n",
    "    label = f\"{row['agent1']} vs {row['agent2']}\"\n",
    "    plt.text(row['pca1'] + 0.02, row['pca2'] + 0.02, label, fontsize=8)\n",
    "\n",
    "plt.title(\"KMeans Clustering of Agent Pair Performance Metrics for Task 1 (PCA-reduced)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Database Connection Config\n",
    "# ---------------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Define the Planning Taxonomy (as in your code)\n",
    "# ---------------------------\n",
    "PLANNING_AGENTS = {\n",
    "    \"Planning Without Feedback\": {\n",
    "        \"Single-Path Reasoning\": [\"Chain of Thought (CoT)\", \"Zero-Shot CoT\", \"Re-Prompting\"],\n",
    "        \"Multi-Path Reasoning\": [\"ReWOO\", \"HuggingGPT\", \"Tree-of-Thought (ToT)\"],\n",
    "        \"External Planner\": [\"LLM-Planner\", \"ReAct\", \"LLM+P\"]\n",
    "    },\n",
    "    \"Planning With Feedback\": {\n",
    "        \"Environment Feedback\": [\"Inner Monologue\", \"LLM4RL\"],\n",
    "        \"Human Feedback\": [\"ChatCoT\", \"TPTU\"],\n",
    "        \"Model Feedback\": [\"Self-Refine\", \"SelfCheck\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a mapping from agent title to its planning sub-category.\n",
    "agent_to_subcat = {}\n",
    "for planning_group in PLANNING_AGENTS.values():\n",
    "    for subcat, agents in planning_group.items():\n",
    "        for agent in agents:\n",
    "            agent_to_subcat[agent] = subcat\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Fetch agent_pair_performance Data from DB\n",
    "# ---------------------------\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_pair = pd.read_sql(\"SELECT * FROM agent_pair_performance ORDER BY task_name, agent1, agent2;\", conn)\n",
    "\n",
    "print(\"Agent Pair Performance Data (first few rows):\")\n",
    "print(df_pair.head())\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Add Planning Taxonomy Labels\n",
    "# ---------------------------\n",
    "# Map agent1 and agent2 to their subcategories.\n",
    "df_pair['agent1_subcat'] = df_pair['agent1'].map(agent_to_subcat)\n",
    "df_pair['agent2_subcat'] = df_pair['agent2'].map(agent_to_subcat)\n",
    "\n",
    "# Create a combined label (sorted alphabetically so that \"A-B\" is the same as \"B-A\")\n",
    "def combine_subcats(row):\n",
    "    cats = sorted([str(row['agent1_subcat']), str(row['agent2_subcat'])])\n",
    "    return \"-\".join(cats)\n",
    "\n",
    "df_pair['pair_category'] = df_pair.apply(combine_subcats, axis=1)\n",
    "print(\"\\nData with Planning Labels:\")\n",
    "print(df_pair[['task_name', 'agent1', 'agent1_subcat', 'agent2', 'agent2_subcat', 'pair_category']].head())\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Prepare Features for Clustering (exclude evaluation_score)\n",
    "# ---------------------------\n",
    "# We use these performance metrics as features.\n",
    "features = ['euclidean_distance', 'cosine_similarity', 'response_length', 'completion_time']\n",
    "X = df_pair[features].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Perform KMeans Clustering\n",
    "# ---------------------------\n",
    "# Choose the number of clusters; for example, k=3.\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df_pair['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "print(\"\\nCluster assignments (first few rows):\")\n",
    "print(df_pair[['task_name', 'agent1', 'agent2', 'cluster']].head())\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Dimensionality Reduction with PCA for Visualization\n",
    "# ---------------------------\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df_pair['pca1'] = X_pca[:, 0]\n",
    "df_pair['pca2'] = X_pca[:, 1]\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Plot the Clustering Results\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(data=df_pair, x='pca1', y='pca2', hue='pair_category', style='cluster', palette='viridis', s=100)\n",
    "\n",
    "# Annotate each point with the agent pair names.\n",
    "for idx, row in df_pair.iterrows():\n",
    "    label = f\"{row['agent1']} vs {row['agent2']}\"\n",
    "    plt.text(row['pca1'] + 0.02, row['pca2'] + 0.02, label, fontsize=8)\n",
    "\n",
    "plt.title(\"KMeans Clustering of Agent Pair Performance (Task-wise) \\n(PCA-reduced Features & Planning Taxonomy Labels)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Pair Category\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# 9) (Optional) Print the final DataFrame for inspection\n",
    "# ---------------------------\n",
    "print(\"\\nFinal Agent Pair Performance with Clusters and Labels:\")\n",
    "print(df_pair.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------\n",
    "# 1) Database Connection Configuration\n",
    "# --------------------------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",  # Replace with your actual password\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# --------------------------------------\n",
    "# 2) Define Complexity Mapping\n",
    "# --------------------------------------\n",
    "# Lower values indicate less complexity (i.e. a better answer).\n",
    "# Adjust these values as needed.\n",
    "complexity_mapping = {\n",
    "    \"Chain of Thought (CoT)\": 4,\n",
    "    \"Zero-Shot CoT\": 4,\n",
    "    \"Re-Prompting\": 4,\n",
    "    \"ReWOO\": 5,\n",
    "    \"HuggingGPT\": 5,\n",
    "    \"Tree-of-Thought (ToT)\": 5,\n",
    "    \"LLM-Planner\": 6,\n",
    "    \"ReAct\": 6,\n",
    "    \"LLM+P\": 6,\n",
    "    \"Inner Monologue\": 1,\n",
    "    \"LLM4RL\": 1,\n",
    "    \"ChatCoT\": 2,\n",
    "    \"TPTU\": 2,\n",
    "    \"Self-Refine\": 3,\n",
    "    \"SelfCheck\": 3\n",
    "}\n",
    "\n",
    "# --------------------------------------\n",
    "# 3) Fetch agent_pair_performance Data for Task 1\n",
    "# --------------------------------------\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    df_pair = pd.read_sql(\"SELECT * FROM agent_pair_performance WHERE task_name = '1';\", conn)\n",
    "\n",
    "print(\"Agent Pair Performance for Task 1 (first few rows):\")\n",
    "print(df_pair.head())\n",
    "\n",
    "# --------------------------------------\n",
    "# 4) Aggregate Performance Metrics Per Agent for Task 1\n",
    "# --------------------------------------\n",
    "# Each row in df_pair is a pairwise comparison between two agents.\n",
    "# We want to compute, for each agent, the average metrics from all pairs in which they appear.\n",
    "agents = set(df_pair['agent1']).union(set(df_pair['agent2']))\n",
    "agent_metrics = []\n",
    "\n",
    "for agent in agents:\n",
    "    # Select rows where the agent appears as either agent1 or agent2\n",
    "    rows = df_pair[(df_pair['agent1'] == agent) | (df_pair['agent2'] == agent)]\n",
    "    if rows.empty:\n",
    "        continue\n",
    "    avg_ed = rows['euclidean_distance'].mean()\n",
    "    avg_cos = rows['cosine_similarity'].mean()\n",
    "    avg_resp_len = rows['response_length'].mean()\n",
    "    avg_comp_time = rows['completion_time'].mean()\n",
    "    # For our combined metric, we simply add average ED and average cosine similarity.\n",
    "    # (You can change this formula as needed.)\n",
    "    combined_metric = avg_ed + avg_cos\n",
    "    # Retrieve the predefined complexity factor; if missing, assign a high default value.\n",
    "    complexity = complexity_mapping.get(agent, 10)\n",
    "    agent_metrics.append({\n",
    "        \"agent\": agent,\n",
    "        \"avg_euclidean_distance\": avg_ed,\n",
    "        \"avg_cosine_similarity\": avg_cos,\n",
    "        \"avg_response_length\": avg_resp_len,\n",
    "        \"avg_completion_time\": avg_comp_time,\n",
    "        \"combined_metric\": combined_metric,\n",
    "        \"complexity\": complexity\n",
    "    })\n",
    "\n",
    "df_agents = pd.DataFrame(agent_metrics)\n",
    "print(\"\\nAggregated Performance Metrics for Each Agent (Task 1):\")\n",
    "print(df_agents)\n",
    "\n",
    "# --------------------------------------\n",
    "# 5) Determine the Best Agent (Least Complex)\n",
    "# --------------------------------------\n",
    "# We define the best answer as the one with the lowest complexity factor.\n",
    "# In case of ties, we choose the one with the lowest combined metric (avg ED + avg cosine similarity).\n",
    "df_agents = df_agents.sort_values(by=[\"complexity\", \"combined_metric\"])\n",
    "best_agent = df_agents.iloc[0]\n",
    "print(\"\\nBest Agent for Task 1 (Based on Least Complexity):\")\n",
    "print(best_agent)\n",
    "\n",
    "# --------------------------------------\n",
    "# 6) Visualize: Scatter Plot of Complexity vs. Combined Metric\n",
    "# --------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_agents['complexity'], df_agents['combined_metric'], s=100, c='skyblue', edgecolors='k')\n",
    "for i, row in df_agents.iterrows():\n",
    "    plt.text(row['complexity'] + 0.05, row['combined_metric'] + 0.05, row['agent'], fontsize=9)\n",
    "plt.xlabel(\"Complexity Factor (Lower is Better)\")\n",
    "plt.ylabel(\"Combined Metric (avg ED + avg Cosine Similarity)\")\n",
    "plt.title(\"Agent Performance for Task 1: Complexity vs Combined Metric\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# New project agent names\n",
    "new_agents = [\n",
    "    \"Chain of Thought (CoT)\", \"Zero-Shot CoT\", \"Re-Prompting\", \"ReWOO\", \"HuggingGPT\",\n",
    "    \"Tree-of-Thought (ToT)\", \"LLM-Planner\", \"ReAct\", \"LLM+P\", \"Inner Monologue\",\n",
    "    \"LLM4RL\", \"ChatCoT\", \"TPTU\", \"Self-Refine\", \"SelfCheck\"\n",
    "]\n",
    "\n",
    "# Set a lower threshold (e.g., 30% of agents)\n",
    "min_threshold = 0.3\n",
    "min_required = int(min_threshold * len(new_agents))\n",
    "\n",
    "score_rows = []\n",
    "tasks_used = []\n",
    "\n",
    "# Loop through all tasks based on the 'idx' column in df\n",
    "for task_id in df[\"idx\"].unique():\n",
    "    row = []\n",
    "    count = 0\n",
    "    for agent in new_agents:\n",
    "        if task_id in task_matrix and agent in task_matrix[task_id]:\n",
    "            score = task_matrix[task_id][agent][\"Total Score\"]\n",
    "            row.append(score)\n",
    "            count += 1\n",
    "        else:\n",
    "            row.append(np.nan)\n",
    "    # Accept tasks with responses from at least min_required agents\n",
    "    if count >= min_required:\n",
    "        row_arr = np.array(row, dtype=np.float64)\n",
    "        # Impute missing scores with the mean of the available ones for this task\n",
    "        mean_val = np.nanmean(row_arr)\n",
    "        row_arr[np.isnan(row_arr)] = mean_val\n",
    "        score_rows.append(row_arr)\n",
    "        tasks_used.append(task_id)\n",
    "\n",
    "if len(score_rows) < 2:\n",
    "    print(\"Not enough tasks with sufficient responses for clustering even with threshold {:.0%}\".format(min_threshold))\n",
    "else:\n",
    "    score_matrix = np.array(score_rows)\n",
    "    scaler = StandardScaler()\n",
    "    score_matrix_scaled = scaler.fit_transform(score_matrix)\n",
    "\n",
    "    # Perform KMeans clustering (using 2 clusters as an example)\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    kmeans.fit(score_matrix_scaled)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Create a DataFrame for the clustering results\n",
    "    df_clusters = pd.DataFrame(score_matrix_scaled, columns=new_agents, index=tasks_used)\n",
    "    df_clusters['Cluster'] = cluster_labels\n",
    "\n",
    "    print(\"\\n🔹 K-Means Cluster Assignment for Each Task:\")\n",
    "    print(df_clusters)\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for agent in new_agents:\n",
    "        plt.scatter(df_clusters.index, df_clusters[agent], c=df_clusters['Cluster'], cmap='viridis', \n",
    "                    label=agent, alpha=0.7)\n",
    "    plt.xlabel('Task Index')\n",
    "    plt.ylabel('Normalized Total Score')\n",
    "    plt.title('🔹 K-Means Clustering: New Project Agent Performance Across Tasks')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import faiss\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Global System Prompt (Shared by All Agents)\n",
    "# =====================================\n",
    "SYSTEM_PROMPT = (\n",
    "    \"Provide only the most relevant factual response in 3-4 sentences (max 350 characters). \"\n",
    "    \"Do NOT include introductions, disclaimers, or statements about being an AI. \"\n",
    "    \"Do NOT include personal beliefs, opinions, or subjective statements. \"\n",
    "    \"Simply state the factual answer.\"\n",
    ")\n",
    "\n",
    "# =====================================\n",
    "# 🔹 PostgreSQL Database Configuration\n",
    "# =====================================\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"agents_db\",\n",
    "    \"user\": \"gauraangmalik\",\n",
    "    \"password\": \"your_password\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Setup Database: Create Tables\n",
    "# =====================================\n",
    "def setup_database():\n",
    "    \"\"\"Sets up the structured database for storing agents, categories, and task performance.\"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS planning_categories (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    name TEXT UNIQUE NOT NULL\n",
    "                );\n",
    "                \n",
    "                CREATE TABLE IF NOT EXISTS planning_subcategories (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    name TEXT UNIQUE NOT NULL,\n",
    "                    category_id INT REFERENCES planning_categories(id) ON DELETE CASCADE\n",
    "                );\n",
    "                \n",
    "                CREATE TABLE IF NOT EXISTS agents (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    title TEXT UNIQUE NOT NULL,\n",
    "                    planning_category_id INT REFERENCES planning_categories(id) ON DELETE CASCADE,\n",
    "                    planning_subcategory_id INT REFERENCES planning_subcategories(id) ON DELETE CASCADE,\n",
    "                    generated_response TEXT[]\n",
    "                );\n",
    "                \n",
    "                CREATE TABLE IF NOT EXISTS task_performance (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    task_name TEXT NOT NULL,\n",
    "                    planning_category_id INT REFERENCES planning_categories(id) ON DELETE CASCADE,\n",
    "                    planning_subcategory_id INT REFERENCES planning_subcategories(id) ON DELETE CASCADE,\n",
    "                    avg_euclidean_distance FLOAT,\n",
    "                    avg_cosine_similarity FLOAT,\n",
    "                    evaluation_score FLOAT,\n",
    "                    completion_time FLOAT,\n",
    "                    response_length INT,\n",
    "                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            conn.commit()\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Store Agent Categories in the Database\n",
    "# =====================================\n",
    "def store_agent_category(agent_name: str, category: str, subcategory: str):\n",
    "    \"\"\"Stores or updates an agent's category in the database.\"\"\"\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT id FROM planning_categories WHERE name = %s\", (category,))\n",
    "            category_id = cursor.fetchone()\n",
    "            \n",
    "            cursor.execute(\"SELECT id FROM planning_subcategories WHERE name = %s\", (subcategory,))\n",
    "            subcategory_id = cursor.fetchone()\n",
    "\n",
    "            if category_id and subcategory_id:\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO agents (title, planning_category_id, planning_subcategory_id, generated_response)\n",
    "                    VALUES (%s, %s, %s, ARRAY[]::TEXT[])\n",
    "                    ON CONFLICT (title) DO NOTHING;\n",
    "                \"\"\", (agent_name, category_id[0], subcategory_id[0]))\n",
    "                conn.commit()\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Planning Agents List (From Paper)\n",
    "# =====================================\n",
    "PLANNING_AGENTS = {\n",
    "    \"Planning Without Feedback\": {\n",
    "        \"Single-Path Reasoning\": [\"Chain of Thought (CoT)\", \"Zero-Shot CoT\", \"Re-Prompting\"],\n",
    "        \"Multi-Path Reasoning\": [\"ReWOO\", \"HuggingGPT\", \"Tree-of-Thought (ToT)\"],\n",
    "        \"External Planner\": [\"LLM-Planner\", \"ReAct\", \"LLM+P\"]\n",
    "    },\n",
    "    \"Planning With Feedback\": {\n",
    "        \"Environment Feedback\": [\"Inner Monologue\", \"LLM4RL\"],\n",
    "        \"Human Feedback\": [\"ChatCoT\", \"TPTU\"],\n",
    "        \"Model Feedback\": [\"Self-Refine\", \"SelfCheck\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Function to Run Agents (Grouped by Category)\n",
    "# =====================================\n",
    "def process_agents(query_text: str, model: str):\n",
    "    \"\"\"Runs all planning agents grouped by category and stores responses.\"\"\"\n",
    "    setup_database()\n",
    "    responses = {}\n",
    "    \n",
    "    for category, subcategories in PLANNING_AGENTS.items():\n",
    "        print(f\"\\n🔹 Running Agents for Category: {category}\\n\")\n",
    "        for subcategory, agents in subcategories.items():\n",
    "            print(f\"  ➤ Subcategory: {subcategory}\")\n",
    "            for agent_name in agents:\n",
    "                print(f\"    🤖 Processing {agent_name}...\")\n",
    "                start_time = time.time()\n",
    "                response = f\"Sample response from {agent_name}\"  # Placeholder\n",
    "                completion_time = time.time() - start_time\n",
    "                response_length = len(response)\n",
    "                responses[agent_name] = (response, completion_time, response_length)\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# =====================================\n",
    "# 🔹 Main Function (Entry Point)\n",
    "# =====================================\n",
    "def main():\n",
    "    model = \"tinyllama\"\n",
    "    query_text = \"Provide a brief overview of quantum computing.\"\n",
    "    responses = process_agents(query_text, model)\n",
    "    \n",
    "    for agent, (response, time_taken, length) in responses.items():\n",
    "        print(f\"\\n✅ {agent} Response: {response}\\n   ⏳ Time Taken: {time_taken:.4f}s | 📝 Response Length: {length} characters\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
